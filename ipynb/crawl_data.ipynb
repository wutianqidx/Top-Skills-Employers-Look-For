{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from urllib import request\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--Company', type=str, default='Amazon', help='Company Name')\n",
    "    parser.add_argument('--JobTitle', type=str, default='SDE', help='Job Title')\n",
    "    parser.add_argument('--JobCount', type=int, default='200', help='Number of Jobs to Study')\n",
    "    #args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    args.DataDir = 'data'\n",
    "    args.UrlDict = {\n",
    "        'AmazonPref': 'https://www.amazon.jobs',\n",
    "        'Amazon': 'https://www.amazon.jobs/en/search?offset={}&result_limit=10&sort=relevant&category[]={}&distanceType=Mi&radius=24km&loc_group_id=seattle-metro&latitude=&longitude=&loc_group_id=seattle-metro&loc_query=Greater%20Seattle%20Area%2C%20WA%2C%20United%20States&base_query=&city=&country=&region=&county=&query_options=&'\n",
    "    }\n",
    "\n",
    "    args.JobDict = {\n",
    "        'AmazonDS': 'data-science',\n",
    "        'AmazonRS': 'research-science',\n",
    "        'AmazonML': 'machine-learning-science',\n",
    "        'AmazonBI': 'business-intelligence',\n",
    "        'AmazonSDE': 'software-development'\n",
    "    }\n",
    "    \n",
    "    return args\n",
    "\n",
    "class Top_Skill():\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.Company = args.Company\n",
    "        self.JobTitle = args.JobTitle\n",
    "        self.JobCount = args.JobCount\n",
    "        self.DataDir = args.DataDir\n",
    "        self.UrlDict = args.UrlDict\n",
    "        self.JobDict = args.JobDict\n",
    "        self.JobCategory = self.JobDict[self.Company + self.JobTitle]\n",
    "        self.Links = None\n",
    "        self.qualifications = None\n",
    "\n",
    "        \n",
    "    \n",
    "    def get_job_links(self):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        Company: string\n",
    "        JobCategory: string\n",
    "        JobCount: int\n",
    "        '''\n",
    "        \n",
    "        job_count = (self.JobCount - 1) // 10 * 10 + 10\n",
    "        offsets = range(0, job_count, 10)\n",
    "        links = []\n",
    "        for offset in offsets:\n",
    "            url = self.UrlDict[self.Company].format(offset, self.JobCategory)\n",
    "            soup = self.get_soup_from_url(url)\n",
    "            for link in soup.find_all('a', {'class': 'job-link'}):\n",
    "                links.append(self.UrlDict[self.Company + 'Pref'] + link.get('href'))\n",
    "        \n",
    "        return links\n",
    "    \n",
    "    def get_soup_from_url(self, url):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        url: string\n",
    "        '''\n",
    "        \n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        driver.close()\n",
    "        \n",
    "        return soup\n",
    "    \n",
    "    def save_links(self):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataDir: string\n",
    "            Path to save data\n",
    "            \n",
    "        Company: string\n",
    "        JobTitle: string\n",
    "        Links: list\n",
    "        '''\n",
    "\n",
    "        if not os.path.exists(self.DataDir):\n",
    "            os.makedirs(self.DataDir)\n",
    "        if not self.Links:\n",
    "            self.Links = self.get_job_links()\n",
    "            \n",
    "        link_dir = self.DataDir + '/' + self.Company + '_' + self.JobTitle + '_Links.txt'\n",
    "            \n",
    "        with open(link_dir, 'w') as f:\n",
    "            for link in self.Links:\n",
    "                f.write(link + '\\n')\n",
    "                \n",
    "                \n",
    "    def get_qualifications(self):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        Company: string\n",
    "        JobCategory: string\n",
    "        Links: list\n",
    "        ''' \n",
    "        \n",
    "        qualifications = []\n",
    "        if not self.Links:\n",
    "            self.save_links()\n",
    "            \n",
    "        for link in self.Links:\n",
    "            requirements, title = self.get_requirements_from_link(link)\n",
    "            basic_qualification = requirements[1].p.get_text()\n",
    "            preferred_qualification = BeautifulSoup(str(requirements[2].p).split('<br/><br/>')[0]).get_text()\n",
    "            qualifications.append(self.Company + '\\t' + self.JobCategory + '\\t' + \\\n",
    "                                  title + '\\t' + basic_qualification + '\\t' + \\\n",
    "                                  preferred_qualification + '\\t' + link)\n",
    "        \n",
    "        return qualifications\n",
    "    \n",
    "    def get_requirements_from_link(self, link):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        Company: string\n",
    "        JobCategory: string\n",
    "        link: string\n",
    "        '''\n",
    "        \n",
    "        response = request.urlopen(link)\n",
    "        page_source = response.read().decode('utf-8')\n",
    "        soup = BeautifulSoup(page_source)\n",
    "        requirements = soup.find_all('div', {'class': 'section'})\n",
    "        title = soup.find_all('h1', {'class': 'title'})[0].get_text()\n",
    "        \n",
    "        return requirements, title\n",
    "        \n",
    "    \n",
    "    def save_qualifications(self):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataDir: string\n",
    "            Path to save data\n",
    "            \n",
    "        Company: string\n",
    "        JobTitle: string\n",
    "        qualifications: list\n",
    "        '''\n",
    "\n",
    "        if not self.qualifications:\n",
    "            self.qualifications = self.get_qualifications()\n",
    "            \n",
    "        data_file_dir = self.DataDir + '/' + self.Company + '_' + self.JobTitle + '_Qualifications.txt'\n",
    "            \n",
    "        with open(data_file_dir, 'w') as f:\n",
    "            f.write('Company\\t' + 'Category\\t' + 'Job_Title\\t' + \\\n",
    "                    'Basic_Qualifications\\t' + \\\n",
    "                    'Preferred_Qualifications\\t' + 'Job_URL\\n')\n",
    "            \n",
    "            for row in self.qualifications:\n",
    "                f.write(row + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    data = Top_Skill(args)\n",
    "    data.save_qualifications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
